{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa10553d",
   "metadata": {},
   "source": [
    "# Customer Sentiment Analysis for restaurant customer reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bece82",
   "metadata": {},
   "source": [
    "### Importing Data\n",
    "\n",
    "#### First, we import the dataset, which is in the form of a TSV file. We can use the pandas library to load the dataset into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086378d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/anaghabhole/Documents/Projects/Sentiment Analysis/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e4c4e",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset:\n",
    "#### Next, we need to preprocess the text data by removing any irrelevant information such as punctuations, numbers, and stopwords. We can use the NLTK library for this task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809e066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anaghabhole/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f648006",
   "metadata": {},
   "source": [
    "### Vectorization:\n",
    "\n",
    "#### To convert the preprocessed text data into numerical data, we use vectorization. We can use the CountVectorizer class from the scikit-learn library for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58ebf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bffc24",
   "metadata": {},
   "source": [
    "### Training and Classification:\n",
    "\n",
    "#### We can now train our predictive models on the preprocessed and vectorized dataset. We will use the Multinomial Naive Bayes, Bernoulli Naive Bayes, and Logistic Regression algorithms to build our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732e02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier_mnb = MultinomialNB()\n",
    "classifier_mnb.fit(X_train, y_train)\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "classifier_bnb = BernoulliNB()\n",
    "classifier_bnb.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "classifier_lr = LogisticRegression(random_state = 0)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set Results\n",
    "y_pred_mnb = classifier_mnb.predict(X_test)\n",
    "y_pred_bnb = classifier_bnb.predict(X_test)\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "# Creating Confusion Matrix\n",
    "cm_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
    "cm_bnb = confusion_matrix(y_test, y_pred_bnb)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c7508",
   "metadata": {},
   "source": [
    "### Analysis Conclusion:\n",
    "#### We can compare the performance of the three models by comparing their confusion matrices. The model with the highest accuracy is the best model for predicting the sentiment of the restaurant reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ce8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Confusion Matrix:\n",
      "[[72 25]\n",
      " [22 81]]\n",
      "Accuracy: 0.765\n",
      "Bernoulli Naive Bayes Confusion Matrix:\n",
      "[[73 24]\n",
      " [22 81]]\n",
      "Accuracy: 0.77\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[76 21]\n",
      " [37 66]]\n",
      "Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Print Multinomial Naive Bayes Confusion Matrix and Accuracy\n",
    "print(\"Multinomial Naive Bayes Confusion Matrix:\")\n",
    "print(cm_mnb) # print confusion matrix\n",
    "accuracy_mnb = (cm_mnb[0][0]+cm_mnb[1][1])/len(y_pred_mnb) # calculate accuracy\n",
    "print(\"Accuracy:\", accuracy_mnb) # print accuracy\n",
    "\n",
    "# Print Bernoulli Naive Bayes Confusion Matrix and Accuracy\n",
    "print(\"Bernoulli Naive Bayes Confusion Matrix:\")\n",
    "print(cm_bnb) # print confusion matrix\n",
    "accuracy_bnb = (cm_bnb[0][0]+cm_bnb[1][1])/len(y_pred_bnb) # calculate accuracy\n",
    "print(\"Accuracy:\", accuracy_bnb) # print accuracy\n",
    "\n",
    "# Print Logistic Regression Confusion Matrix and Accuracy\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(cm_lr) # print confusion matrix\n",
    "accuracy_lr = (cm_lr[0][0]+cm_lr[1][1])/len(y_pred_lr) # calculate accuracy\n",
    "print(\"Accuracy:\", accuracy_lr) # print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f4589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
